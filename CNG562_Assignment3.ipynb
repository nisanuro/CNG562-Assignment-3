{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNG562_Assignment3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisanuro/CNG562-Assignment-3/blob/master/CNG562_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKiuqTOPUoYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "from sklearn import metrics, datasets, preprocessing\n",
        "from sklearn.datasets import load_breast_cancer \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv4LWKTaXUFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correlation_map(df):\n",
        "    plt.figure(figsize=(20,12)) \n",
        "\n",
        "    corr = df.corr()\n",
        "    sns.heatmap(corr, annot=True, cmap='hot')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSdDSDTJXXvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_features(data, feature_indexes):\n",
        "\t\t# eliminate above column indices from the data and return new set\n",
        "\t\tfiltered_data = np.delete(data, feature_indexes, axis=1)\n",
        "\n",
        "\t\treturn filtered_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFxmZa8fXeR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fourError(X, Y, model, r, future_scaling):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = r, stratify=Y)\n",
        "    \n",
        "    if(future_scaling):\n",
        "        sc = StandardScaler()\n",
        "        X_train = sc.fit_transform(X_train)\n",
        "        X_test = sc.transform(X_test)\n",
        "    \n",
        "    Train_x, TrainDev_x, Train_y, TrainDev_y = train_test_split(X_train, Y_train, test_size=0.2, random_state=0, stratify=Y_train)\n",
        "    Dev_x, Test_x, Dev_y, Test_y = train_test_split(X_test, Y_test, test_size=0.5, random_state=0, stratify=Y_test)\n",
        "\n",
        "    model.fit(Train_x, Train_y)\n",
        "\n",
        "    y_true, trainDev_pred = TrainDev_y, model.predict(TrainDev_x)\n",
        "\n",
        "    print(\"\\nTrain-Train Dev,   e1:\", metrics.mean_squared_error(TrainDev_y, trainDev_pred))\n",
        "    print(\"Accuracy: \", 1 - metrics.mean_squared_error(TrainDev_y, trainDev_pred),\"\\n\")\n",
        "\n",
        "    y_true, dev_pred = Dev_y, model.predict(Dev_x)\n",
        "    print(\"Train-Dev,   e2\", metrics.mean_squared_error(Dev_y, dev_pred))\n",
        "    print(\"Accuracy: \", 1 - metrics.mean_squared_error(Dev_y, dev_pred),\"\\n\")\n",
        "\n",
        "    y_true, test_pred = Test_y, model.predict(Test_x)\n",
        "    print(\"Train-Test,   e3: \", metrics.mean_squared_error(Test_y, test_pred))\n",
        "    print(\"Accuracy: \", 1 - metrics.mean_squared_error(Test_y, test_pred),\"\\n\")\n",
        "\n",
        "    y_true, devTest_pred = Y_test, model.predict(X_test)\n",
        "    print(\"Train-(Dev+Test),   e4: \", metrics.mean_squared_error(Y_test, devTest_pred))\n",
        "    print(\"Accuracy: \", 1 - metrics.mean_squared_error(Y_test, devTest_pred),\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-6caNUiYCRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vis_all_feat(data, class_):\n",
        "    for col_ind in range(data.shape[1]):\n",
        "\t\t    print(\"Viewing Feature #{0}\".format(str(col_ind)))\n",
        "\t\t    vis_single_feat(data, class_, col_ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oiSxcKlaVoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vis_single_feat(data, class_, ind):\n",
        "\t  # create graph of classification and feature values\t\n",
        "\t  plt.figure(100) # display two plots on separate figures\n",
        "\t  df = pd.DataFrame(data)\n",
        "\t  feat_vals = df.iloc[:, ind]\n",
        "\t  plt.scatter(feat_vals, class_)\n",
        "\t  plt.title(\"Plot of Feature {0}\".format(str(ind)))\n",
        "\t  plt.xlabel(\"Feature Value\")\n",
        "\t  plt.ylabel(\"Classification\")\n",
        "  \n",
        "\t  # create bar graph of mean feature values for each classification\n",
        "\t  plt.figure(200)\n",
        "\t  plt.title(\"Mean Values of Feature {0}\".format(str(ind)))\n",
        "\t  plt.xlabel(\"Classification\")\n",
        "\t  plt.ylabel(\"Mean Feature Value\")\n",
        "\t  mean_df = pd.concat([df.iloc[:, ind], pd.Series(class_)], axis=1)\n",
        "\t  mean_df.columns = [\"values\", \"classif\"]\t\n",
        "\t  mean_df.groupby(\"classif\", as_index=False)[\"values\"].mean().loc[:,\"values\"].plot(kind='bar')\n",
        "  \n",
        "\t  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_rIt_ZdfqDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dbScan(X, Y, eps = 0.5, min = 5, distance = \"euclidean\"):\n",
        "    dbs = DBSCAN(eps=eps, min_samples=min, metric=distance, algorithm=\"brute\", n_jobs=-1)\n",
        "    \n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0, stratify=Y)\n",
        "    \n",
        "    pred = dbs.fit_predict(X_train)\n",
        "\n",
        "    score = silhouette_score(X_train, pred)\n",
        "\n",
        "    print(\"Score: {}\".format(score))\n",
        "    #print(confusion_matrix(Y_train, pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRLldXbodvDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_eps():\n",
        "    neigh = NearestNeighbors(n_neighbors=4)\n",
        "    nbrs = neigh.fit(X)\n",
        "    distances, indices = nbrs.kneighbors(X)\n",
        "\n",
        "    distances = np.sort(distances, axis=0)\n",
        "    distances = distances[:,1]\n",
        "    plt.plot(distances)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRJed7fflAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model(X, Y):\n",
        "    eps = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
        "    for i in eps:\n",
        "        dbScan(X, Y, eps=i)\n",
        "    #eps = 0.8\n",
        "    \n",
        "    #for i in range(1, 7):\n",
        "    #    dbScan(X, Y, eps=0.6, min = i)\n",
        "    #min = 2,3\n",
        "    \n",
        "    metric = [\"euclidean\", \"manhattan\"]\n",
        "\n",
        "    #for i in metric:\n",
        "    #    dbScan(X, Y, eps=0.8, min=1, distance=i)\n",
        "    #euclidean, chebyshev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An-MeMXd3cNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(X_train, X_test, Y_train, Y_test):\n",
        "    model = DBSCAN(eps=0.8, min_samples=2, metric=\"euclidean\", algorithm=\"brute\", n_jobs=-1)\n",
        "\n",
        "    #pred = model.predict(X_test)\n",
        "    #print(confusion_matrix(Y_test, pred))\n",
        "    prediction = model.fit_predict(X_train)\n",
        "\n",
        "    correct = 0\n",
        "    for i in range(len(Y_train)):\n",
        "        if prediction[i] == Y_train[i]:\n",
        "            correct += 1\n",
        "\n",
        "    print(correct/len(X_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tchSjgwb1STZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ElbowMethod(data):\n",
        "    Sum_of_squared_distances = []\n",
        "    K = range(1,15)\n",
        "    for k in K:\n",
        "        km = KMeans(n_clusters=k, n_init=10, n_jobs=-1, random_state = 0)\n",
        "        km = km.fit(data)\n",
        "        Sum_of_squared_distances.append(km.inertia_)\n",
        "    \n",
        "    plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
        "    plt.xlabel('k')\n",
        "    plt.ylabel('Sum_of_squared_distances')\n",
        "    plt.title('Elbow Method For Optimal k')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW8EztXK1WrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SilhouetteAnalysis(X, Y):\n",
        "    range_n_clusters = [2, 3, 4]\n",
        "\n",
        "    for n_clusters in range_n_clusters:\n",
        "        \n",
        "        # Create a subplot with 1 row and 2 columns\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "        fig.set_size_inches(18, 7)\n",
        "\n",
        "        # The 1st subplot is the silhouette plot\n",
        "        # The silhouette coefficient can range from -1, 1 but in this example all\n",
        "        # lie within [-0.1, 1]\n",
        "        ax1.set_xlim([-0.1, 1])\n",
        "        # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "        # plots of individual clusters, to demarcate them clearly.\n",
        "        ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "        \n",
        "        # Initialize the clusterer with n_clusters value and a random generator\n",
        "        # seed of 10 for reproducibility.\n",
        "        clusterer = KMeans(n_clusters=n_clusters, n_init=10, n_jobs=-1,random_state = 0)\n",
        "        cluster_labels = clusterer.fit_predict(X)\n",
        "        \n",
        "        # The silhouette_score gives the average value for all the samples.\n",
        "        # This gives a perspective into the density and separation of the formed\n",
        "        # clusters\n",
        "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "        \n",
        "        print(\"For n_clusters =\", n_clusters,\n",
        "            \"The average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "\n",
        "        \n",
        "        # Compute the silhouette scores for each sample\n",
        "        sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "        y_lower = 10\n",
        "        for i in range(n_clusters):\n",
        "            # Aggregate the silhouette scores for samples belonging to\n",
        "            # cluster i, and sort them\n",
        "            ith_cluster_silhouette_values = \\\n",
        "                sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "            ith_cluster_silhouette_values.sort()\n",
        "\n",
        "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "            y_upper = y_lower + size_cluster_i\n",
        "\n",
        "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                            0, ith_cluster_silhouette_values,\n",
        "                            facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "            # Label the silhouette plots with their cluster numbers at the middle\n",
        "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "            # Compute the new y_lower for next plot\n",
        "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "        ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "        # The vertical line for average silhouette score of all the values\n",
        "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "        # 2nd Plot showing the actual clusters formed\n",
        "        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "        ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                    c=colors, edgecolor='k')\n",
        "\n",
        "        # Labeling the clusters\n",
        "        centers = clusterer.cluster_centers_\n",
        "        # Draw white circles at cluster centers\n",
        "        ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
        "                    c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "        for i, c in enumerate(centers):\n",
        "            ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
        "                        s=50, edgecolor='k')\n",
        "\n",
        "        ax2.set_title(\"The visualization of the clustered data.\")\n",
        "        ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "        ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "        plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                    \"with n_clusters = %d\" % n_clusters),\n",
        "                    fontsize=14, fontweight='bold')\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sinv7_SC1ZfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Kmeans(X_train, X_test, Y_train, Y_test):\n",
        "\n",
        "    model = KMeans(n_clusters=2, n_init=10, n_jobs=-1, random_state = 0)\n",
        "    model.fit(X_train)\n",
        "\n",
        "    pred = model.predict(X_test)\n",
        "    #print(confusion_matrix(Y_test, pred))\n",
        "    \n",
        "    correct = 0\n",
        "    for i in range(len(X_train)):\n",
        "        predict_me = np.array(X_train[i].astype(float))\n",
        "        predict_me = predict_me.reshape(-1, len(predict_me))\n",
        "        prediction = model.predict(predict_me)\n",
        "        if prediction[0] == Y_train[i]:\n",
        "            correct += 1\n",
        "\n",
        "    print(correct/len(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS38fnJIa0jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    breast_cancer = datasets.load_breast_cancer()\n",
        "    X = breast_cancer.data\n",
        "    Y = breast_cancer.target\n",
        "    \n",
        "    X = filter_features(X, [2, 3, 20, 22, 23, 12, 13])\n",
        "\n",
        "    #vis_all_feat(X, Y)\n",
        "    X = filter_features(X, [1, 2, 6, 7, 9, 10, 14, 15])\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(X)\n",
        "    X = scaler.transform(X)\n",
        "    #optimize_eps()\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
        "    #acc(X_train, X_test, Y_train, Y_test)\n",
        "    #optimize_model(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DSqEtYr6I95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2882633-3b83-4c4c-fbab-6c7f3157a715"
      },
      "source": [
        "    #ElbowMethod(X_train) \n",
        "    #SilhouetteAnalysis(X_train, Y_train)\n",
        "    \n",
        "    Kmeans(X_train, X_test, Y_train, Y_test)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7258347978910369\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}